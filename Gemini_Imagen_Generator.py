from __future__ import annotations

import json
import torch
from typing import List, Dict, Optional, Tuple, Any
import re
import random
import time
import threading
import os
import sys
from datetime import datetime

MODULE_DIR = os.path.dirname(os.path.abspath(__file__))
if MODULE_DIR not in sys.path:
    sys.path.insert(0, MODULE_DIR)

# åœ¨é ComfyUI è¿è¡Œç¯å¢ƒä¸­,server å¯èƒ½æ— æ³•æ­£å¸¸å¯¼å…¥
# è¿™é‡Œåšä¸€ä¸ªå…¼å®¹å¤„ç†:å¯¼å…¥å¤±è´¥æ—¶æä¾›ä¸€ä¸ªå ä½ PromptServer,
# ä»…ç”¨äºé¿å…æµ‹è¯•è„šæœ¬å¯¼å…¥æœ¬æ¨¡å—æ—¶æŠ¥é”™
try:
    from server import PromptServer
except ImportError:
    class _DummyPromptServer:
        instance = None
    PromptServer = _DummyPromptServer()

import comfy.utils
import comfy.model_management

from logger import logger
from config_manager import ConfigManager
from balance_service import BalanceService
from image_codec import ImageCodec, ErrorCanvas
from api_client import GeminiApiClient
from task_runner import BatchGenerationRunner


CONFIG_MANAGER = ConfigManager(MODULE_DIR)
API_CLIENT = GeminiApiClient(CONFIG_MANAGER, logger)
BALANCE_SERVICE = BalanceService(API_CLIENT, CONFIG_MANAGER, logger)

class BananaImageNode:
    """
    ComfyUIèŠ‚ç‚¹: NanoBananaå›¾åƒç”Ÿæˆï¼Œé€‚é…Geminiå…¼å®¹ç«¯ç‚¹
    æ”¯æŒä»config.iniè¯»å–API Key
    """

    RETURN_TYPES = ("IMAGE", "STRING")
    RETURN_NAMES = ("images", "text")
    FUNCTION = "generate_images"
    OUTPUT_NODE = True
    CATEGORY = "image/ai_generation"

    def __init__(self):
        self.config_manager = CONFIG_MANAGER
        self.image_codec = ImageCodec(logger, self._ensure_not_interrupted)
        self.error_canvas = ErrorCanvas(logger)
        self.balance_service = BALANCE_SERVICE
        self.task_runner = BatchGenerationRunner(
            logger,
            self._ensure_not_interrupted,
            lambda total: comfy.utils.ProgressBar(total),
        )

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "prompt": ("STRING", {
                    "multiline": True,
                    "default": "Peace and love"
                }),
                "api_key": ("STRING", {
                    "default": "",
                    "multiline": False
                }),
                "model_type": ("STRING", {
                    "default": "gemini-2.5-flash-image"
                }),
                "batch_size": ("INT", {
                    "default": 1, "min": 1, "max": 8
                }),
                "aspect_ratio": (["Auto", "1:1", "9:16", "16:9", "21:9", "2:3", "3:2", "3:4", "4:3", "4:5", "5:4"], {
                    "default": "Auto"
                }),
            },
            "optional": {
                "seed": ("INT", {
                    "default": -1,
                    "min": -1,
                    "max": 102400,
                    "control_after_generate": True
                }),
                "top_p": ("FLOAT", {
                    "default": 0.95, "min": 0.0, "max": 1.0, "step": 0.01
                }),
                "image_1": ("IMAGE",),
                "image_2": ("IMAGE",),
                "image_3": ("IMAGE",),
                "image_4": ("IMAGE",),
                "image_5": ("IMAGE",),
            }
        }
    
    @staticmethod
    def _ensure_not_interrupted():
        """ç»Ÿä¸€çš„ä¸­æ–­æ£€æŸ¥ï¼Œå¤ç”¨ ComfyUI åŸç”Ÿå–æ¶ˆæœºåˆ¶"""
        comfy.model_management.throw_exception_if_processing_interrupted()

    def _build_failure_result(self, index: int, seed: int, error_msg: str) -> Dict[str, Any]:
        """æ„é€ ç»Ÿä¸€çš„å¤±è´¥è¿”å›ç»“æ„ï¼Œä¾¿äºä¸Šå±‚èšåˆå¤„ç†"""
        return {
            "index": index,
            "success": False,
            "error": error_msg,
            "seed": seed,
            "tensor": None,
            "image_count": 0,
        }

    def generate_single_image(self, args):
        """ç”Ÿæˆå•å¼ å›¾ç‰‡ï¼ˆç”¨äºå¹¶å‘ï¼‰"""
        (
            i,
            current_seed,
            api_key,
            prompt,
            model_type,
            aspect_ratio,
            top_p,
            input_images_b64,
            timeout,
            stagger_delay,
            decode_workers,
        ) = args

        self._ensure_not_interrupted()
        if stagger_delay > 0:
            delay = i * stagger_delay
            if delay > 0:
                time.sleep(delay)

        thread_id = threading.current_thread().name
        logger.info(f"æ‰¹æ¬¡ {i+1} å¼€å§‹è¯·æ±‚...")

        try:
            self._ensure_not_interrupted()
            request_data = API_CLIENT.create_request_data(
                prompt,
                current_seed,
                aspect_ratio,
                top_p,
                input_images_b64
            )
            self._ensure_not_interrupted()
            effective_base_url = self.config_manager.get_effective_api_base_url()
            response_data = API_CLIENT.send_request(
                api_key,
                request_data,
                model_type,
                effective_base_url,
                timeout
            )
            self._ensure_not_interrupted()
            base64_images, text_content = API_CLIENT.extract_content(response_data)
            decoded_tensor = None
            decoded_count = 0
            if base64_images:
                self._ensure_not_interrupted()
                decoded_tensor = self.image_codec.base64_to_tensor_parallel(
                    base64_images,
                    log_prefix=f"[{thread_id}] æ‰¹æ¬¡ {i+1}",
                    max_workers=decode_workers
                )
                decoded_count = decoded_tensor.shape[0]

            # æ›´æ˜æ˜¾åœ°åŒºåˆ†â€œæœ‰å›¾è¿”å›â€å’Œâ€œæœªè¿”å›ä»»ä½•å›¾ç‰‡â€çš„æƒ…å†µ
            if decoded_count > 0:
                logger.success(f"æ‰¹æ¬¡ {i+1} å®Œæˆ - ç”Ÿæˆ {decoded_count} å¼ å›¾ç‰‡")
            else:
                # ç®€åŒ–æ—¥å¿—è¾“å‡º,å°½å¯èƒ½ç»™å‡ºç”¨æˆ·èƒ½ç†è§£çš„åŸå› è¯´æ˜
                reason = ""
                # 1. æ£€æŸ¥ finishReason ä¿¡æ¯
                try:
                    if isinstance(response_data, dict):
                        candidates = response_data.get("candidates") or []
                        if candidates and isinstance(candidates[0], dict):
                            finish_reason = candidates[0].get("finishReason") or ""
                            if finish_reason:
                                if finish_reason == "NO_IMAGE":
                                    reason = "æ¨¡å‹æœªç”Ÿæˆä»»ä½•å›¾ç‰‡ï¼ˆfinishReason=NO_IMAGEï¼Œä¸€èˆ¬è¡¨ç¤ºå½“å‰æç¤ºæˆ–å‚è€ƒå›¾ä¸è§¦å‘å›¾åƒè¾“å‡ºï¼Œå¯èƒ½æ˜¯å†…å®¹è¢«è¿‡æ»¤æˆ–æœªé€šè¿‡å®‰å…¨å®¡æŸ¥ï¼‰"
                                else:
                                    reason = f"æ¨¡å‹æœªç”Ÿæˆå›¾ç‰‡ï¼ˆfinishReason={finish_reason}ï¼‰"
                except Exception:
                    # å¦‚æœè§£æ finishReason å¤±è´¥,å¿½ç•¥å³å¯
                    pass

                # 2. å¦‚æœæœ‰æ–‡æœ¬å†…å®¹,è¡¥å……å±•ç¤ºä¸€å°æ®µ
                brief_text = (text_content or "").strip().replace("\n", " ")
                if brief_text:
                    if reason:
                        reason = f"{reason}ï¼›æ¨¡å‹è¿”å›æ–‡æœ¬: {brief_text[:100]}"
                    else:
                        reason = f"æ¨¡å‹ä»…è¿”å›æ–‡æœ¬: {brief_text[:100]}"

                # 3. éƒ½æ²¡æœ‰å°±ç»™ä¸€ä¸ªé€šç”¨è¯´æ˜
                if not reason:
                    reason = "æ¨¡å‹æœªç»™å‡ºå›¾ç‰‡æˆ–è¯´æ˜æ–‡æœ¬ï¼Œå¯èƒ½æ˜¯æœåŠ¡ç«¯ç­–ç•¥æˆ–å‚æ•°è®¾ç½®å¯¼è‡´æœ¬æ¬¡æœªäº§å‡ºå›¾ç‰‡"

                logger.warning(f"æ‰¹æ¬¡ {i+1} å®Œæˆï¼Œä½†æœªè¿”å›ä»»ä½•å›¾ç‰‡ã€‚{reason}")

            return {
                'index': i,
                'success': True,
                'images': base64_images,
                'tensor': decoded_tensor,
                'image_count': decoded_count,
                'text': text_content,
                'seed': current_seed
            }
        except comfy.model_management.InterruptProcessingException:
            logger.warning(f"æ‰¹æ¬¡ {i+1} å·²å–æ¶ˆ")
            raise
        except Exception as e:
            error_msg = str(e)[:200]
            logger.error(f"æ‰¹æ¬¡ {i+1} å¤±è´¥")
            logger.error(f"é”™è¯¯: {error_msg}")
            return self._build_failure_result(i, current_seed, error_msg)

    def generate_images(self, prompt, api_key="", model_type="gemini-2.5-flash-image",
                       batch_size=1, aspect_ratio="Auto", seed=-1, top_p=0.95, max_workers=None,
                       image_1=None, image_2=None, image_3=None,
                       image_4=None, image_5=None):

        # è§£æ API Keyï¼šä¼˜å…ˆä½¿ç”¨èŠ‚ç‚¹è¾“å…¥ï¼Œç•™ç©ºæ—¶å›é€€ config
        sanitized_input_key = self.config_manager.sanitize_api_key(api_key)
        resolved_api_key = sanitized_input_key or self.config_manager.sanitize_api_key(
            self.config_manager.load_api_key()
        )

        # éªŒè¯API key
        if not resolved_api_key:
            error_msg = "è¯·åœ¨ config.ini ä¸­é…ç½® API Key æˆ–åœ¨èŠ‚ç‚¹ä¸­å¡«å†™"
            logger.error(error_msg)
            error_tensor = self.error_canvas.build_error_tensor_from_text(
                "é…ç½®ç¼ºå¤±",
                f"{error_msg}\nè¯·åœ¨ config.ini æˆ–èŠ‚ç‚¹è¾“å…¥ä¸­å¡«å†™æœ‰æ•ˆ API Key"
            )
            return (error_tensor, error_msg)

        # ç»Ÿä¸€ä½¿ç”¨å†…éƒ¨éšè—çš„ Base URLï¼ˆä¸æ¥å—å‰ç«¯ä¼ å…¥ï¼‰
        effective_base_url = self.config_manager.get_effective_api_base_url()

        cost_factor = self.config_manager.load_cost_factor()
        balance_summary = self.balance_service.get_cached_balance_text(effective_base_url, resolved_api_key, cost_factor)

        start_time = time.time()
        raw_input_images = [image_1, image_2, image_3, image_4, image_5]
        input_tensors = [img for img in raw_input_images if img is not None]
        encoded_input_images = self.image_codec.prepare_input_images(input_tensors)

        # å›ºå®šé…ç½®
        concurrent_mode = True   # æ€»æ˜¯å¼€å¯å¹¶å‘
        # ä¸ºç½‘ç»œè¯·æ±‚å¢åŠ è½»å¾®äº¤é”™å»¶è¿Ÿ,å‡å°‘ç¬æ—¶è¯·æ±‚å°–å³°
        stagger_delay = 0.2      # æ¯ä¸ªæ‰¹æ¬¡ç›¸å¯¹å‰ä¸€ä¸ªå»¶è¿Ÿ 0.2 ç§’
        # æ‹†åˆ†ç½‘ç»œè¶…æ—¶ï¼šè¿æ¥(20s) + è¯»å–(90s)
        # è¿æ¥è¶…æ—¶è®¾ç½®ä¸º20sï¼Œåœ¨ä»£ç†/ä¸ç¨³å®šç½‘ç»œä¸‹æ›´å®½å®¹
        # è¯»å–è¶…æ—¶ä¿æŒ90sï¼Œå› ä¸ºå›¾åƒç”Ÿæˆç¡®å®éœ€è¦æ—¶é—´
        connect_timeout = 20
        read_timeout = 90
        request_timeout = (connect_timeout, read_timeout)
        continue_on_error = True  # æ€»æ˜¯å®¹é”™
        configured_workers = self.config_manager.load_max_workers()
        decode_workers = max(1, configured_workers)

        if seed == -1:
            base_seed = random.randint(0, 102400)
        else:
            base_seed = seed

        decoded_tensors: List[torch.Tensor] = []
        total_generated_images = 0
        all_texts: List[str] = []
        results: List[Dict[str, Any]] = []
        tasks: List[Tuple[Any, ...]] = []

        for i in range(batch_size):
            current_seed = base_seed + i if seed != -1 else -1
            tasks.append((i, current_seed, resolved_api_key, prompt, model_type, aspect_ratio,
                          top_p, encoded_input_images, request_timeout, stagger_delay,
                          decode_workers))

        # æ˜¾ç¤ºä»»åŠ¡å¼€å§‹ä¿¡æ¯
        logger.header("ğŸ¨ Gemini å›¾åƒç”Ÿæˆä»»åŠ¡")
        logger.info(f"æ‰¹æ¬¡æ•°é‡: {batch_size} å¼ ")
        logger.info(f"å›¾ç‰‡æ¯”ä¾‹: {aspect_ratio}")
        if seed != -1:
            logger.info(f"éšæœºç§å­: {seed}")
        if top_p != 0.95:
            logger.info(f"Top-P å‚æ•°: {top_p}")
        logger.separator()

        configured_network_cap = self.config_manager.load_network_workers_cap()
        network_workers_cap = min(configured_workers, configured_network_cap)
        actual_workers = min(network_workers_cap, batch_size) if concurrent_mode and batch_size > 1 else 1
        actual_workers = max(1, actual_workers)

        def progress_callback(result: Dict[str, Any], completed_count: int, total_count: int, progress_bar: object):
            if result.get('success'):
                logger.success(
                    f"[{completed_count}/{total_count}] æ‰¹æ¬¡ {result['index']+1} å®Œæˆ"
                )
            else:
                batch_label = result.get('index', -1)
                batch_text = "?" if batch_label < 0 else batch_label + 1
                logger.error(
                    f"[{completed_count}/{total_count}] æ‰¹æ¬¡ {batch_text} å¤±è´¥"
                )

            preview_tensor = result.get('tensor')
            if result.get('success') and preview_tensor is not None:
                preview_tuple = self.image_codec.build_preview_tuple(
                    preview_tensor, result['index']
                )
                if preview_tuple is not None:
                    progress_bar.update_absolute(completed_count, total_count, preview_tuple)
                else:
                    progress_bar.update(1)
            else:
                progress_bar.update(1)

        results = self.task_runner.run(
            tasks,
            self.generate_single_image,
            batch_size,
            actual_workers,
            continue_on_error,
            progress_callback,
        )

        if not results:
            error_text = f"æœªç”Ÿæˆä»»ä½•å›¾åƒ\næ€»è€—æ—¶: {time.time() - start_time:.2f}s"
            if balance_summary:
                error_text = f"{balance_summary}\n\n{error_text}"
            logger.error(error_text)
            error_tensor = self.error_canvas.build_error_tensor_from_text("ç”Ÿæˆå¤±è´¥", error_text)
            return (error_tensor, error_text)

        results.sort(key=lambda x: x['index'])

        for result in results:
            if result.get('success'):
                tensor = result.get('tensor')
                if tensor is not None:
                    decoded_tensors.append(tensor)
                    total_generated_images += result.get('image_count', tensor.shape[0])
                if result.get('text'):
                    all_texts.append(f"[æ‰¹æ¬¡ {result['index']+1}] {result['text']}")
            else:
                error_msg = f"[æ‰¹æ¬¡ {result['index']+1}] âŒ {result.get('error', 'æœªçŸ¥é”™è¯¯')}"
                all_texts.append(error_msg)
                if not continue_on_error:
                    break

        total_time = time.time() - start_time

        if not decoded_tensors or total_generated_images == 0:
            error_text = f"æœªç”Ÿæˆä»»ä½•å›¾åƒ\næ€»è€—æ—¶: {total_time:.2f}s\n\n" + "\n".join(all_texts)
            if balance_summary:
                error_text = f"{balance_summary}\n\n{error_text}"
            logger.error(error_text)
            error_tensor = self.error_canvas.build_error_tensor_from_text("ç”Ÿæˆå¤±è´¥", error_text)
            return (error_tensor, error_text)

        if len(decoded_tensors) == 1:
            image_tensor = decoded_tensors[0]
        else:
            image_tensor = torch.cat(decoded_tensors, dim=0)

        actual_count = total_generated_images
        ratio_text = "è‡ªåŠ¨" if aspect_ratio == "Auto" else aspect_ratio
        success_info = f"âœ… æˆåŠŸç”Ÿæˆ {actual_count} å¼ å›¾åƒï¼ˆæ¯”ä¾‹: {ratio_text}ï¼‰"
        avg_time = total_time / actual_count if actual_count > 0 else 0
        time_info = f"æ€»è€—æ—¶: {total_time:.2f}sï¼Œå¹³å‡ {avg_time:.2f}s/å¼ "
        if actual_count != batch_size:
            time_info += f" âš ï¸ è¯·æ±‚{batch_size}å¼ ï¼Œå®é™…ç”Ÿæˆ{actual_count}å¼ "
            # è‹¥å®é™…ç”Ÿæˆæ•°é‡å°‘äºè¯·æ±‚æ•°é‡ï¼Œåœ¨æ—¥å¿—ä¸­é¢å¤–ç»™å‡ºæ˜æ˜¾æç¤º
            logger.warning(f"éƒ¨åˆ†æ‰¹æ¬¡æœªè¿”å›å›¾ç‰‡ï¼šè¯·æ±‚ {batch_size} å¼ ï¼Œå®é™…ä¸Šåªç”Ÿæˆ {actual_count} å¼ ï¼Œè¯·æŸ¥çœ‹ä¸Šæ–¹å„æ‰¹æ¬¡æ—¥å¿—ä¸­çš„â€œæœªè¿”å›ä»»ä½•å›¾ç‰‡â€æç¤º")

        combined_text = f"{success_info}\n{time_info}"
        if all_texts:
            combined_text += "\n\n" + "\n".join(all_texts)
        if balance_summary:
            combined_text = f"{balance_summary}\n\n{combined_text}"

        # æ˜¾ç¤ºå®Œæˆç»Ÿè®¡
        logger.summary("ä»»åŠ¡å®Œæˆ", {
            "æ€»æ‰¹æ¬¡": f"{batch_size} ä¸ª",
            "æˆåŠŸç”Ÿæˆ": f"{actual_count} å¼ ",
            "æ€»è€—æ—¶": f"{total_time:.2f}s",
            "å¹³å‡é€Ÿåº¦": f"{avg_time:.2f}s/å¼ "
        })

        return (image_tensor, combined_text)

# æ³¨å†ŒèŠ‚ç‚¹
NODE_CLASS_MAPPINGS = {"BananaImageNode": BananaImageNode}
NODE_DISPLAY_NAME_MAPPINGS = {"BananaImageNode": "å¿ƒå®â¤Banana"}

BALANCE_SERVICE.ensure_route(lambda: getattr(PromptServer, "instance", None))



