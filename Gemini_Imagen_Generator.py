import json
import requests
import base64
from io import BytesIO
from PIL import Image, ImageDraw, ImageFont
import numpy as np
import torch
from typing import List, Dict, Optional, Tuple, Any
import re
import random
import time
import textwrap
from concurrent.futures import ThreadPoolExecutor, as_completed, wait, FIRST_COMPLETED
import threading
import os
import configparser
import asyncio
import hashlib
from datetime import datetime
from functools import partial
from collections import OrderedDict
from requests.adapters import HTTPAdapter
from aiohttp import web

# åœ¨é ComfyUI è¿è¡Œç¯å¢ƒä¸­,server å¯èƒ½æ— æ³•æ­£å¸¸å¯¼å…¥
# è¿™é‡Œåšä¸€ä¸ªå…¼å®¹å¤„ç†:å¯¼å…¥å¤±è´¥æ—¶æä¾›ä¸€ä¸ªå ä½ PromptServer,
# ä»…ç”¨äºé¿å…æµ‹è¯•è„šæœ¬å¯¼å…¥æœ¬æ¨¡å—æ—¶æŠ¥é”™
try:
    from server import PromptServer
except ImportError:
    class _DummyPromptServer:
        instance = None
    PromptServer = _DummyPromptServer()

import comfy.utils
import comfy.model_management

# å¯¼å…¥æ–°çš„æ—¥å¿—ç³»ç»Ÿ
try:
    from .logger import logger
except ImportError:
    # å¦‚æœç›¸å¯¹å¯¼å…¥å¤±è´¥ï¼Œå°è¯•ç»å¯¹å¯¼å…¥
    import sys
    import os
    # ç¡®ä¿å½“å‰ç›®å½•åœ¨ sys.path ä¸­
    current_dir = os.path.dirname(os.path.abspath(__file__))
    if current_dir not in sys.path:
        sys.path.insert(0, current_dir)
    from logger import logger



def retry_with_backoff(tries=3, delay=2, backoff=2, retriable_exceptions=None,
                       fast_fail_threshold=20.0):
    """
    æ™ºèƒ½é‡è¯•è£…é¥°å™¨ï¼ŒåŒºåˆ†å¿«é€Ÿå¤±è´¥å’Œæ…¢é€Ÿå¤±è´¥

    Args:
        tries: æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆåŒ…æ‹¬åˆæ¬¡å°è¯•ï¼‰
        delay: åˆå§‹å»¶è¿Ÿæ—¶é—´ï¼ˆç§’ï¼‰
        backoff: é€€é¿å€æ•°
        retriable_exceptions: å¯é‡è¯•çš„å¼‚å¸¸ç±»å‹åˆ—è¡¨ï¼Œé»˜è®¤ä¸ºç½‘ç»œç›¸å…³å¼‚å¸¸
        fast_fail_threshold: å¿«é€Ÿå¤±è´¥é˜ˆå€¼ï¼ˆç§’ï¼‰ï¼Œè¶…è¿‡æ­¤æ—¶é—´çš„å¤±è´¥ä¸é‡è¯•
    """
    if retriable_exceptions is None:
        # é»˜è®¤é‡è¯•å¯æ¢å¤çš„é”™è¯¯ï¼ˆ5xxã€ç½‘ç»œè¶…æ—¶ã€è¿æ¥ä¸­æ–­ã€å¸¸è§IOé”™è¯¯ï¼‰
        retriable_exceptions = (
            requests.exceptions.Timeout,
            requests.exceptions.ConnectionError,
            requests.exceptions.HTTPError,
            requests.exceptions.ChunkedEncodingError,  # å“åº”åˆ†å—ä¼ è¾“ä¸­æ–­
            requests.exceptions.RequestException,       # å…œåº•çš„ç½‘ç»œå¼‚å¸¸
            ConnectionResetError,                       # è¿æ¥è¢«é‡ç½®
            BrokenPipeError,                            # ç®¡é“ç ´è£‚
            TimeoutError,                               # Python å†…ç½®è¶…æ—¶é”™è¯¯ï¼ˆä¾‹å¦‚å†™æ“ä½œè¶…æ—¶ï¼‰
            OSError,                                    # å…¶ä»–åº•å±‚ç½‘ç»œ/IOé”™è¯¯
        )

    def decorator(func):
        from functools import wraps

        @wraps(func)
        def wrapper(*args, **kwargs):
            mtries, mdelay = tries, delay

            for attempt in range(mtries):
                attempt_start = time.time()
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    attempt_duration = time.time() - attempt_start
                    error_str = str(e)
                    # ä¸ºæ—¥å¿—è¾“å‡ºæ„å»ºä¸€ä¸ªè„±æ•åçš„é”™è¯¯ä¿¡æ¯,é¿å…æ³„éœ²æºç«™/å¯†é’¥ç­‰æ•æ„ŸURL
                    # ä»…ç”¨äºæ—¥å¿—å±•ç¤º,ä¸å½±å“åç»­åŸºäºåŸå§‹ error_str çš„åˆ¤å®šé€»è¾‘
                    sanitized_error_str = re.sub(
                        r"https?://[^\s'\"ï¼‰)]+",
                        "[URL]",
                        error_str
                    )

                    # æ£€æŸ¥æ˜¯å¦æ˜¯å¯é‡è¯•çš„å¼‚å¸¸
                    is_retriable = False
                    error_type = "æœªçŸ¥é”™è¯¯"

                    # æ£€æŸ¥è¶…æ—¶é”™è¯¯ - å¦‚æœè€—æ—¶è¶…è¿‡é˜ˆå€¼,ä¸é‡è¯•
                    if "è¯·æ±‚è¶…æ—¶" in error_str or isinstance(e, requests.exceptions.Timeout):
                        if attempt_duration >= fast_fail_threshold:
                            logger.error(f"è¯·æ±‚è¶…æ—¶ ({attempt_duration:.1f}s)ï¼Œè€—æ—¶è¿‡é•¿ï¼Œä¸é‡è¯•")
                            raise
                        is_retriable = True
                        error_type = "è¶…æ—¶é”™è¯¯(å¿«é€Ÿ)"

                    # æ£€æŸ¥ 5xx æœåŠ¡å™¨é”™è¯¯ - åªæœ‰å¿«é€Ÿè¿”å›çš„æ‰é‡è¯•
                    elif "APIè¿”å› 5" in error_str:
                        if attempt_duration >= fast_fail_threshold:
                            logger.error(f"æœåŠ¡å™¨é”™è¯¯ ({attempt_duration:.1f}s)ï¼ŒæœåŠ¡å™¨å¤„ç†æ—¶é—´è¿‡é•¿ï¼Œä¸é‡è¯•")
                            raise
                        is_retriable = True
                        error_type = "5xxæœåŠ¡å™¨é”™è¯¯"

                    # æ£€æŸ¥ 429 é™æµé”™è¯¯ - å€¼å¾—é‡è¯•
                    elif "APIè¿”å› 429" in error_str or "rate limit" in error_str.lower():
                        is_retriable = True
                        error_type = "APIé™æµ"
                        mdelay = max(mdelay, 5)  # é™æµæ—¶è‡³å°‘ç­‰5ç§’

                    # æ£€æŸ¥ 502/503/504 ç½‘å…³é”™è¯¯ - ä¸´æ—¶æ€§é—®é¢˜,å€¼å¾—é‡è¯•
                    elif any(code in error_str for code in ["502", "503", "504"]):
                        if attempt_duration < fast_fail_threshold:
                            is_retriable = True
                            error_type = "ç½‘å…³é”™è¯¯"

                    # æ£€æŸ¥è¿æ¥ä¸­æ–­ç›¸å…³é”™è¯¯
                    elif "IncompleteRead" in str(type(e)) or "IncompleteRead" in error_str:
                        is_retriable = True
                        error_type = "å“åº”ä¸å®Œæ•´"

                    # æ£€æŸ¥å“åº”è¿‡æ—©ç»“æŸ
                    elif "Response ended prematurely" in error_str:
                        is_retriable = True
                        error_type = "å“åº”ä¸­æ–­"

                    # æ£€æŸ¥è¿æ¥é”™è¯¯
                    elif isinstance(e, requests.exceptions.ConnectionError):
                        if attempt_duration < fast_fail_threshold:
                            is_retriable = True
                            error_type = "è¿æ¥é”™è¯¯"

                    # æ£€æŸ¥æ˜¯å¦æ˜¯é¢„å®šä¹‰çš„å¯é‡è¯•å¼‚å¸¸
                    elif isinstance(e, retriable_exceptions):
                        if attempt_duration < fast_fail_threshold:
                            is_retriable = True
                            error_type = "ç½‘ç»œå¼‚å¸¸"

                    # æœ€åä¸€æ¬¡å°è¯•æˆ–ä¸å¯é‡è¯•çš„é”™è¯¯ï¼Œç›´æ¥æŠ›å‡º
                    if attempt == mtries - 1 or not is_retriable:
                        if not is_retriable:
                            logger.error(f"ä¸å¯é‡è¯•çš„é”™è¯¯: {sanitized_error_str[:200]}")
                        raise

                    # æ‰“å°é‡è¯•ä¿¡æ¯
                    logger.warning(
                        f"{error_type} (å°è¯• {attempt + 1}/{mtries}, è€—æ—¶ {attempt_duration:.1f}s): "
                        f"{sanitized_error_str[:200]}"
                    )
                    logger.info(f"ç­‰å¾… {mdelay:.1f}s åé‡è¯•...")

                    # ç­‰å¾…åé‡è¯•
                    time.sleep(mdelay)
                    mdelay *= backoff  # æŒ‡æ•°é€€é¿

        return wrapper
    return decorator


class BananaImageNode:
    """
    ComfyUIèŠ‚ç‚¹: NanoBananaå›¾åƒç”Ÿæˆï¼Œé€‚é…Geminiå…¼å®¹ç«¯ç‚¹
    æ”¯æŒä»config.iniè¯»å–API Key
    """

    # API Base URL ç¼–ç ç›¸å…³å¸¸é‡ï¼ˆé»˜è®¤ç»‘å®šåˆ° https://api.aabao.topï¼‰
    # ä¸ºé¿å…åœ¨ä»£ç ä¸­å‡ºç°æ˜æ–‡ URLï¼Œä»…ä¿å­˜å­—ç¬¦ç¼–ç åˆ—è¡¨
    _ENC_KEY_PARTS = (3, 4)
    _DEFAULT_API_BASE_URL_CODEPOINTS = [104, 116, 116, 112, 115, 58, 47, 47, 97, 112, 105, 46, 97, 97, 98, 97, 111, 46, 116, 111, 112]
    _CONFIG_SECTION = "gemini"
    _CONFIG_KEY_API_BASE_URL_ENC = "api_base_url_enc"

    TOKENS_PER_RATE = 100000
    CURRENCY_PER_RATE = 0.20
    BASE_COST_PER_TOKEN = CURRENCY_PER_RATE / TOKENS_PER_RATE
    _BALANCE_CACHE: Dict[str, Dict[str, Any]] = {}
    _BALANCE_CACHE_LOCK = threading.Lock()
    _BALANCE_ROUTE_REGISTERED = False
    _BALANCE_ROUTE_TIMER: Optional[threading.Timer] = None
    _BALANCE_CACHE_TTL = 60.0
    _IMAGE_B64_CACHE: "OrderedDict[str, str]" = OrderedDict()
    _IMAGE_CACHE_LOCK = threading.Lock()
    _IMAGE_CACHE_SIZE = 16
    _ERROR_FONT_CACHE: Dict[int, ImageFont.ImageFont] = {}
    _THREAD_LOCAL = threading.local()
    _SESSION_INIT_LOCK = threading.Lock()
    _SESSION_INITIALIZED = False
    _PLACEHOLDER_KEYS = {
        "your-api-key-here",
        "your_api_key_here",
        "yourapikeyhere"
    }
    # æœ¬åœ°æµ‹è¯•é…ç½®ç›¸å…³å¸¸é‡
    _TEST_CONFIG_FILE_NAME = "banana_gemini_test.local.ini"
    _TEST_CONFIG_SECTION = "gemini_test"
    _TEST_MODE_ENV_VAR = "BANANA_GEMINI_USE_LOCAL_TEST"

    RETURN_TYPES = ("IMAGE", "STRING")
    RETURN_NAMES = ("images", "text")
    FUNCTION = "generate_images"
    OUTPUT_NODE = True
    CATEGORY = "image/ai_generation"

    @classmethod
    def _decode_api_base_url(cls, enc: str) -> str:
        """å°†ç¼–ç åçš„ Base URL è¿˜åŸä¸ºæ˜æ–‡ï¼Œä»…åœ¨è¿è¡Œæ—¶ä½¿ç”¨"""
        raw = base64.b64decode(enc.encode("utf-8"))
        key = 0
        for part in cls._ENC_KEY_PARTS:
            key ^= part
        data = bytes((b ^ key) for b in raw)
        return data.decode("utf-8")

    @classmethod
    def _get_default_base_url(cls) -> str:
        """
        é€šè¿‡å­—ç¬¦ç¼–ç åˆ—è¡¨æ„é€ é»˜è®¤ Base URLï¼Œé¿å…åœ¨ä»£ç ä¸­å‡ºç°æ˜æ–‡ URL
        """
        return "".join(chr(c) for c in cls._DEFAULT_API_BASE_URL_CODEPOINTS)

    @classmethod
    def _get_effective_api_base_url(cls) -> str:
        """
        ç»Ÿä¸€è®¡ç®—å½“å‰ç”Ÿæ•ˆçš„ API Base URLã€‚

        ä¼˜å…ˆçº§ï¼š
        1. è‹¥å¼€å¯æµ‹è¯•æ¨¡å¼ä¸”æœ¬åœ°æµ‹è¯•é…ç½®ä¸­å­˜åœ¨ api_base_url_encï¼Œåˆ™ä½¿ç”¨è¯¥å€¼
        2. è‹¥ config.ini çš„ [gemini] æ®µä¸­é…ç½®äº† api_base_url_encï¼Œåˆ™ä½¿ç”¨è¯¥å€¼
        3. å¦åˆ™å›é€€åˆ°ç±»å†…ç½®çš„é»˜è®¤å€¼
        """
        # 1. æµ‹è¯•æ¨¡å¼ä¼˜å…ˆï¼ˆç”¨äºä¸´æ—¶å¼€å‘/è°ƒè¯•ï¼‰
        test_base_url = cls._load_test_base_url()
        if test_base_url:
            return test_base_url

        # 2. æ­£å¸¸é…ç½®æ–‡ä»¶ä¸­çš„æ°¸ä¹… Base URLï¼ˆç¼–ç å½¢å¼ï¼‰
        config_path = cls._get_config_path()
        parser = configparser.ConfigParser()
        if os.path.exists(config_path):
            try:
                parser.read(config_path, encoding="utf-8")
                if parser.has_section(cls._CONFIG_SECTION):
                    enc = parser.get(
                        cls._CONFIG_SECTION,
                        cls._CONFIG_KEY_API_BASE_URL_ENC,
                        fallback=""
                    ).strip()
                    if enc:
                        return cls._decode_api_base_url(enc)
            except Exception as e:
                logger.warning(
                    f"è¯»å– config ä¸­çš„ {cls._CONFIG_KEY_API_BASE_URL_ENC} å¤±è´¥: {e}"
                )

        # 3. é»˜è®¤å€¼
        return cls._get_default_base_url()

    @classmethod
    def _sanitize_api_key(cls, api_key: Optional[str]) -> Optional[str]:
        if not api_key:
            return None
        cleaned = api_key.strip()
        if not cleaned:
            return None

        normalized = cleaned.lower()
        compact = re.sub(r"[\s_-]+", "", normalized)
        if normalized in cls._PLACEHOLDER_KEYS or compact in cls._PLACEHOLDER_KEYS:
            return None
        return cleaned

    @staticmethod
    def _clamp_cost_factor(cost_factor: Optional[float]) -> float:
        if cost_factor is None:
            return 1.0
        try:
            value = float(cost_factor)
        except (TypeError, ValueError):
            return 1.0
        return max(0.0001, min(value, 100.0))

    @classmethod
    def _balance_cache_key(cls, api_base_url: str, api_key: str) -> str:
        base_url = api_base_url or cls._get_effective_api_base_url()
        normalized_url = base_url.rstrip("/").lower()
        digest = hashlib.sha256(api_key.encode("utf-8")).hexdigest()
        return f"{normalized_url}|{digest}"

    @classmethod
    def _tensor_cache_key(cls, tensor: Optional[torch.Tensor] = None,
                          np_data: Optional[np.ndarray] = None) -> Optional[str]:
        if tensor is None and np_data is None:
            return None
        try:
            target = np_data
            if target is None:
                target = tensor.detach().cpu().numpy()
            return hashlib.sha1(target.tobytes()).hexdigest()
        except Exception:
            return None

    @classmethod
    def _get_cached_image_b64(cls, cache_key: Optional[str]) -> Optional[str]:
        if not cache_key:
            return None
        with cls._IMAGE_CACHE_LOCK:
            value = cls._IMAGE_B64_CACHE.get(cache_key)
            if value is not None:
                cls._IMAGE_B64_CACHE.move_to_end(cache_key)
            return value

    @classmethod
    def _set_cached_image_b64(cls, cache_key: Optional[str], value: str) -> None:
        if not cache_key or not value:
            return
        with cls._IMAGE_CACHE_LOCK:
            cls._IMAGE_B64_CACHE[cache_key] = value
            cls._IMAGE_B64_CACHE.move_to_end(cache_key)
            while len(cls._IMAGE_B64_CACHE) > cls._IMAGE_CACHE_SIZE:
                cls._IMAGE_B64_CACHE.popitem(last=False)

    @classmethod
    def _store_balance_snapshot(cls, api_base_url: str, api_key: str, payload: Dict[str, Any]) -> None:
        sanitized_key = cls._sanitize_api_key(api_key)
        if not sanitized_key:
            return
        cache_key = cls._balance_cache_key(api_base_url, sanitized_key)
        snapshot = {
            "payload": payload,
            "fetched_at": time.time()
        }
        with cls._BALANCE_CACHE_LOCK:
            cls._BALANCE_CACHE[cache_key] = snapshot

    @classmethod
    def _get_balance_snapshot(cls, api_base_url: str, api_key: str) -> Optional[Dict[str, Any]]:
        sanitized_key = cls._sanitize_api_key(api_key)
        if not sanitized_key:
            return None
        cache_key = cls._balance_cache_key(api_base_url, sanitized_key)
        with cls._BALANCE_CACHE_LOCK:
            return cls._BALANCE_CACHE.get(cache_key)

    @classmethod
    def _snapshot_age_seconds(cls, snapshot: Optional[Dict[str, Any]]) -> Optional[float]:
        if not snapshot:
            return None
        fetched_at = snapshot.get("fetched_at")
        if not fetched_at:
            return None
        return max(0.0, time.time() - fetched_at)

    @classmethod
    def _is_balance_snapshot_stale(cls, snapshot: Optional[Dict[str, Any]]) -> bool:
        age = cls._snapshot_age_seconds(snapshot)
        if age is None:
            return True
        return age > cls._BALANCE_CACHE_TTL

    @classmethod
    def _schedule_route_registration(cls):
        if cls._BALANCE_ROUTE_TIMER is not None and cls._BALANCE_ROUTE_TIMER.is_alive():
            return

        def _retry():
            cls._BALANCE_ROUTE_TIMER = None
            cls.ensure_balance_route()

        timer = threading.Timer(1.0, _retry)
        timer.daemon = True
        cls._BALANCE_ROUTE_TIMER = timer
        timer.start()

    @staticmethod
    def _parse_bool(value: Optional[str]) -> bool:
        if value is None:
            return False
        return value.lower() in {"1", "true", "yes", "on"}

    @classmethod
    def ensure_balance_route(cls):
        if cls._BALANCE_ROUTE_REGISTERED:
            return
        prompt_server = getattr(PromptServer, "instance", None)
        if prompt_server is None:
            cls._schedule_route_registration()
            return

        @prompt_server.routes.get("/banana/token_usage")
        async def handle_token_usage(request):
            # å‰ç«¯ä¸å†æ§åˆ¶ Base URLï¼Œç»Ÿä¸€ç”±åç«¯éšè—ç®¡ç†
            base_url = cls._get_effective_api_base_url()
            refresh = cls._parse_bool(request.rel_url.query.get("refresh"))
            # ä¼˜å…ˆä½¿ç”¨å‰ç«¯ä¼ é€’çš„API Key,å¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„Key
            api_key_from_request = request.rel_url.query.get("api_key", "").strip()
            api_key = cls._sanitize_api_key(api_key_from_request) or cls._sanitize_api_key(cls.load_config())
            cost_factor = cls.load_cost_factor_from_config()
            # è¿è¡Œäº aiohttp handler ä¸Šä¸‹æ–‡,ä¼˜å…ˆä½¿ç”¨è¿è¡Œä¸­çš„ loop
            loop = asyncio.get_running_loop()

            if not refresh:
                snapshot = cls._get_balance_snapshot(base_url, api_key)
                if snapshot is None:
                    return web.json_response({
                        "success": False,
                        "message": "æš‚æ— ä½™é¢ç¼“å­˜ï¼Œè¯·ç‚¹å‡»â€œæŸ¥è¯¢ä½™é¢â€æŒ‰é’®åˆ·æ–°",
                        "cached": False,
                        "stale": True
                    })

                summary = cls.format_balance_summary(snapshot, cost_factor, include_stale_hint=True)
                return web.json_response({
                    "success": True,
                    "data": snapshot.get("payload", {}).get("data"),
                    "raw": snapshot.get("payload"),
                    "summary": summary,
                    "cost_factor": cost_factor,
                    "cached": True,
                    "stale": cls._is_balance_snapshot_stale(snapshot)
                })

            try:
                await loop.run_in_executor(
                    None,
                    partial(cls.fetch_token_usage, base_url, api_key)
                )
                snapshot = cls._get_balance_snapshot(base_url, api_key)
                if snapshot is None:
                    raise RuntimeError("ä½™é¢ç¼“å­˜æ›´æ–°å¤±è´¥")
                summary = cls.format_balance_summary(snapshot, cost_factor)
                return web.json_response({
                    "success": True,
                    "data": snapshot.get("payload", {}).get("data"),
                    "raw": snapshot.get("payload"),
                    "summary": summary,
                    "cost_factor": cost_factor,
                    "cached": False,
                    "stale": False
                })
            except Exception as exc:
                return web.json_response(
                    {"success": False, "message": str(exc)},
                    status=400
                )

        cls._BALANCE_ROUTE_REGISTERED = True

    @staticmethod
    def _format_number(value: Optional[float]) -> str:
        if value is None:
            return "-"
        if isinstance(value, (int, float)):
            return f"{value:,.0f}"
        return str(value)

    @classmethod
    def _format_cost(cls, tokens: Optional[float], cost_factor: float) -> str:
        if tokens is None:
            return "-"
        try:
            tokens_value = float(tokens)
        except (TypeError, ValueError):
            return "-"
        # ä½¿ç”¨ cost_factor çš„å€’æ•°: å½“é…ç½®ä¸º 1.67 æ—¶,å®é™…é™¤ä»¥ 1.67
        yuan = tokens_value * cls.BASE_COST_PER_TOKEN / cost_factor
        return f"Â¥{yuan:.4f}"

    @classmethod
    def _format_expiry(cls, timestamp: Optional[int]) -> str:
        if not timestamp or timestamp <= 0:
            return "ä¸è¿‡æœŸ"
        try:
            dt = datetime.fromtimestamp(timestamp)
            return dt.strftime("%Y-%m-%d %H:%M")
        except Exception:
            return str(timestamp)

    @classmethod
    def format_balance_summary(cls, snapshot: Dict[str, Any], cost_factor: float = 1.0,
                               include_stale_hint: bool = False) -> str:
        cost_factor = cls._clamp_cost_factor(cost_factor)
        data = snapshot.get("payload", {}).get("data", {})
        available = cls._format_number(data.get("total_available"))
        used = cls._format_number(data.get("total_used"))
        granted = cls._format_number(data.get("total_granted"))
        unlimited = "æ˜¯" if data.get("unlimited_quota") else "å¦"
        expires = cls._format_expiry(data.get("expires_at"))
        available_cost = cls._format_cost(data.get("total_available"), cost_factor)
        used_cost = cls._format_cost(data.get("total_used"), cost_factor)
        fetched_at = snapshot.get("fetched_at")
        if fetched_at:
            fetched_text = datetime.fromtimestamp(fetched_at).strftime("%H:%M")
        else:
            fetched_text = datetime.now().strftime("%H:%M")
        summary_lines = [
            f"ğŸ”‘ æŸ¥è¯¢æ—¶é—´ {fetched_text}",
            f"ä¼°ç®—è´¹ç”¨: å¯ç”¨ {available_cost} / å·²ç”¨ {used_cost} (ä»…å‚è€ƒ)",
            f"åˆ°æœŸ: {expires}"
        ]
        if include_stale_hint and cls._is_balance_snapshot_stale(snapshot):
            age = cls._snapshot_age_seconds(snapshot)
            if age is not None:
                summary_lines.append(
                    f"âš ï¸ ä½™é¢ä¿¡æ¯å·² {int(age)}s æœªåˆ·æ–°ï¼Œç‚¹å‡»èŠ‚ç‚¹æŒ‰é’®è·å–æœ€æ–°æ•°æ®"
                )
        return "\n".join(summary_lines)

    @classmethod
    def get_cached_balance_text(cls, api_base_url: str, api_key: str, cost_factor: float = 1.0) -> Optional[str]:
        snapshot = cls._get_balance_snapshot(api_base_url, api_key)
        if not snapshot:
            return None
        try:
            return cls.format_balance_summary(snapshot, cost_factor, include_stale_hint=True)
        except Exception:
            return None

    @classmethod
    def _get_thread_session(cls) -> requests.Session:
        """
        è·å–çº¿ç¨‹ä¸“å±çš„ HTTP Sessionï¼Œé¿å… requests.Session åœ¨çº¿ç¨‹é—´å¤ç”¨å¯¼è‡´çš„ç«æ€
        """
        session = getattr(cls._THREAD_LOCAL, "session", None)
        if session is not None:
            return session

        pool_size = max(4, cls.load_max_workers_from_config())
        session = requests.Session()

        adapter = HTTPAdapter(
            pool_connections=pool_size,
            pool_maxsize=pool_size,
            pool_block=False
        )
        session.mount("http://", adapter)
        session.mount("https://", adapter)

        # ä½¿ç”¨çŸ­è¿æ¥ç­–ç•¥: æ¯ä¸ªè¯·æ±‚ç»“æŸåä¸»åŠ¨å…³é—­è¿æ¥,é¿å…åœ¨ä»£ç†/ä¸ç¨³å®šç½‘ç»œä¸‹é•¿è¿æ¥æ‚¬æŒ‚
        # æ³¨æ„: requests ä»ä¼šç®¡ç†åº•å±‚è¿æ¥æ± ,ä½†é€šè¿‡ Connection: close æç¤ºä¸­é—´èŠ‚ç‚¹ä¸è¦é•¿æœŸä¿æŒè¿æ¥
        session.headers.update({
            'Connection': 'close',
        })

        setattr(cls._THREAD_LOCAL, "session", session)

        with cls._SESSION_INIT_LOCK:
            if not cls._SESSION_INITIALIZED:
                logger.info(f"HTTP è¿æ¥æ± å·²åˆå§‹åŒ–: pool_size={pool_size}, connection=close")
                cls._SESSION_INITIALIZED = True

        return session

    @classmethod
    def fetch_token_usage(cls, api_base_url: str, api_key: str, timeout: int = 15) -> Dict[str, Any]:
        sanitized_key = cls._sanitize_api_key(api_key)
        if not sanitized_key:
            raise ValueError("æœªé…ç½®æœ‰æ•ˆçš„ API Key")
        base_url = (api_base_url or cls._get_effective_api_base_url()).rstrip("/")
        url = f"{base_url}/api/usage/token"
        headers = {"Authorization": f"Bearer {sanitized_key}"}
        session = cls._get_thread_session()
        # ç›´æ¥å‘é€è¯·æ±‚,Sessionä¼šè‡ªåŠ¨ç®¡ç†è¿æ¥æ± 
        response = session.get(url, headers=headers, timeout=timeout)
        try:
            try:
                response.raise_for_status()
            except requests.HTTPError as exc:
                raise RuntimeError(f"ä½™é¢æŸ¥è¯¢å¤±è´¥: HTTP {response.status_code}") from exc
            try:
                payload = response.json()
            except json.JSONDecodeError as exc:
                raise RuntimeError("ä½™é¢æŸ¥è¯¢å¤±è´¥: å“åº”é JSON") from exc
        finally:
            # ç¡®ä¿å“åº”å†…å®¹è¢«å®Œå…¨è¯»å–,è¿æ¥æ‰èƒ½è¢«å¤ç”¨
            response.close()
        cls._store_balance_snapshot(base_url, sanitized_key, payload)
        return payload

    @staticmethod
    def _get_config_path() -> str:
        current_dir = os.path.dirname(os.path.abspath(__file__))
        return os.path.join(current_dir, "config.ini")

    @classmethod
    def _get_test_config_path(cls) -> str:
        """è·å–æœ¬åœ°æµ‹è¯•é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆbanana_gemini_test.local.iniï¼‰"""
        current_dir = os.path.dirname(os.path.abspath(__file__))
        return os.path.join(current_dir, cls._TEST_CONFIG_FILE_NAME)

    @classmethod
    def _is_test_mode_enabled(cls) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦å¼€å¯æœ¬åœ°æµ‹è¯•æ¨¡å¼

        é€šè¿‡ç¯å¢ƒå˜é‡ BANANA_GEMINI_USE_LOCAL_TEST æ§åˆ¶ï¼š
        - 1/true/yes/onï¼ˆå¤§å°å†™ä¸æ•æ„Ÿï¼‰è§†ä¸ºå¼€å¯
        """
        value = os.environ.get(cls._TEST_MODE_ENV_VAR, "").strip().lower()
        return value in {"1", "true", "yes", "on"}

    @classmethod
    def _load_test_section(cls) -> Optional[Dict[str, str]]:
        """
        ä»æœ¬åœ°æµ‹è¯•é…ç½®æ–‡ä»¶ä¸­è¯»å– [gemini_test] æ®µ

        ä»…åœ¨æµ‹è¯•æ¨¡å¼å¼€å¯æ—¶å°è¯•è¯»å–ï¼›è¯»å–å¤±è´¥ä¼šè®°å½•æ—¥å¿—ä½†ä¸ä¸­æ–­æ­£å¸¸æµç¨‹ã€‚
        """
        if not cls._is_test_mode_enabled():
            return None

        test_config_path = cls._get_test_config_path()
        if not os.path.exists(test_config_path):
            return None

        parser = configparser.ConfigParser()
        try:
            parser.read(test_config_path, encoding="utf-8")
            if parser.has_section(cls._TEST_CONFIG_SECTION):
                section = parser[cls._TEST_CONFIG_SECTION]
                # è½¬æˆæ™®é€šå­—å…¸ï¼Œé¿å…æŠŠ ConfigParser çš„ç»†èŠ‚æ³„éœ²åˆ°å¤–å±‚
                return {k: v for k, v in section.items()}
        except Exception as e:
            logger.warning(f"è¯»å–æœ¬åœ°æµ‹è¯•é…ç½®å¤±è´¥: {e}")
        return None

    @classmethod
    def _load_test_api_key(cls) -> Optional[str]:
        """ä»æœ¬åœ°æµ‹è¯•é…ç½®ä¸­è¯»å–å¹¶æ¸…æ´— API Key"""
        section = cls._load_test_section()
        if not section:
            return None
        api_key = section.get("api_key", "").strip()
        return cls._sanitize_api_key(api_key)

    @classmethod
    def _load_test_base_url(cls) -> Optional[str]:
        """ä»æœ¬åœ°æµ‹è¯•é…ç½®ä¸­è¯»å–å¹¶è§£ç  Base URLï¼ˆç¼–ç å­—æ®µ api_base_url_encï¼‰"""
        section = cls._load_test_section()
        if not section:
            return None
        enc = section.get("api_base_url_enc", "").strip()
        if not enc:
            return None
        try:
            return cls._decode_api_base_url(enc)
        except Exception as e:
            logger.warning(f"è§£ç æµ‹è¯•é…ç½®ä¸­çš„ api_base_url_enc å¤±è´¥: {e}")
            return None

    @classmethod
    def _load_test_python_env(cls) -> Optional[str]:
        """
        ä»æœ¬åœ°æµ‹è¯•é…ç½®ä¸­è¯»å– ComfyUI Python ç¯å¢ƒè·¯å¾„

        ç›®å‰ä»…ä½œä¸ºè°ƒè¯•/å¤–éƒ¨è„šæœ¬è°ƒç”¨æ—¶çš„å‚è€ƒï¼Œä¸åœ¨èŠ‚ç‚¹è¿è¡Œé€»è¾‘ä¸­è‡ªåŠ¨ä½¿ç”¨ã€‚
        """
        section = cls._load_test_section()
        if not section:
            return None
        python_env = section.get("python_env", "").strip()
        return python_env or None

    @classmethod
    def load_network_workers_cap_from_config(cls) -> int:
        """
        ä» config.ini è¯»å–ç½‘ç»œå¹¶å‘ä¸Šé™

        é…ç½®é¡¹:
        [gemini]
        network_workers_cap = 4

        ä»…ç”¨äºé™åˆ¶åŒæ—¶å‘èµ·çš„ç½‘ç»œè¯·æ±‚æ•°é‡,é¿å…åœ¨ä¸ç¨³å®šæœåŠ¡å•†ä¸Šäº§ç”Ÿè¯·æ±‚é£æš´ã€‚
        æœ€ç»ˆå¹¶å‘åº¦ä¼šåœ¨ [1, 8] èŒƒå›´å†…è¢«å¤¹ç´§ã€‚
        """
        config_path = cls._get_config_path()
        parser = configparser.ConfigParser()
        default_cap = 4

        if os.path.exists(config_path):
            try:
                parser.read(config_path, encoding="utf-8")
                if parser.has_section("gemini"):
                    value = parser.getint("gemini", "network_workers_cap", fallback=default_cap)
                    # é˜²æ­¢é…ç½®å¼‚å¸¸,å¯¹å¹¶å‘ä¸Šé™åšåˆç†çº¦æŸ
                    return max(1, min(value, 8))
            except Exception as e:
                logger.warning(f"è¯»å– config ä¸­çš„ network_workers_cap å¤±è´¥: {e}")

        return default_cap

    @classmethod
    def load_config(cls):
        """ä»config.iniåŠ è½½API key"""
        config_path = cls._get_config_path()

        config = configparser.ConfigParser()

        # é»˜è®¤API key
        default_api_key = "your-api-key-here"

        # è‹¥å¼€å¯æµ‹è¯•æ¨¡å¼ï¼Œä¼˜å…ˆä»æœ¬åœ°æµ‹è¯•é…ç½®è¯»å– API Key
        test_api_key = cls._load_test_api_key()
        if test_api_key:
            return test_api_key

        # å°è¯•è¯»å–é…ç½®æ–‡ä»¶
        if os.path.exists(config_path):
            try:
                config.read(config_path, encoding='utf-8')
                if config.has_section('gemini'):
                    return config.get('gemini', 'api_key', fallback=default_api_key)
            except Exception as e:
                logger.warning(f"è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        else:
            # åˆ›å»ºç¤ºä¾‹é…ç½®æ–‡ä»¶
            try:
                cpu_limit = max(1, os.cpu_count() or 4)
                default_workers = min(8, cpu_limit)
                config['gemini'] = {
                    'api_key': 'your-api-key-here',
                    'balance_cost_factor': '0.6',
                    'max_workers': str(default_workers)
                }
                with open(config_path, 'w', encoding='utf-8') as f:
                    config.write(f)
                logger.success(f"å·²åˆ›å»ºç¤ºä¾‹é…ç½®æ–‡ä»¶: {config_path}")
                logger.info(f"è¯·ç¼–è¾‘æ–‡ä»¶å¹¶å¡«å…¥ä½ çš„ API Key")
            except Exception as e:
                logger.warning(f"åˆ›å»ºé…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        
        return default_api_key

    @classmethod
    def load_cost_factor_from_config(cls) -> float:
        config_path = cls._get_config_path()
        config = configparser.ConfigParser()
        if os.path.exists(config_path):
            try:
                config.read(config_path, encoding="utf-8")
                if config.has_section('gemini'):
                    value = config.getfloat('gemini', 'balance_cost_factor', fallback=0.6)
                    return cls._clamp_cost_factor(value)
            except Exception as e:
                logger.warning(f"è¯»å– config ä¸­çš„ balance_cost_factor å¤±è´¥: {e}")
        return 0.6

    @classmethod
    def load_max_workers_from_config(cls) -> int:
        cpu_limit = max(1, os.cpu_count() or 1)
        default_workers = min(8, cpu_limit)
        config_path = cls._get_config_path()
        config = configparser.ConfigParser()
        if os.path.exists(config_path):
            try:
                config.read(config_path, encoding="utf-8")
                if config.has_section('gemini'):
                    value = config.getint('gemini', 'max_workers', fallback=default_workers)
                    return max(1, min(value, cpu_limit))
            except Exception as e:
                logger.warning(f"è¯»å– config ä¸­çš„ max_workers å¤±è´¥: {e}")
        return default_workers

    @classmethod
    def _get_keepalive_timeout(cls) -> int:
        """
        ä» config.ini è¯»å– Keep-Alive è¶…æ—¶æ—¶é—´
        é»˜è®¤ 30 ç§’ï¼Œå…¼å®¹å¤§å¤šæ•°é˜²ç«å¢™/NAT ç¯å¢ƒ
        """
        config_path = cls._get_config_path()
        config = configparser.ConfigParser()

        if os.path.exists(config_path):
            try:
                config.read(config_path, encoding="utf-8")
                if config.has_section('gemini'):
                    timeout = config.getint('gemini', 'keepalive_timeout', fallback=30)
                    # é™åˆ¶åœ¨åˆç†èŒƒå›´ï¼š10-120 ç§’
                    return max(10, min(timeout, 120))
            except Exception as e:
                logger.warning(f"è¯»å– keepalive_timeout å¤±è´¥: {e}")

        return 30  # é»˜è®¤ 30 ç§’

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "prompt": ("STRING", {
                    "multiline": True,
                    "default": "Peace and love"
                }),
                "api_key": ("STRING", {
                    "default": "",
                    "multiline": False
                }),
                "model_type": ("STRING", {
                    "default": "gemini-2.5-flash-image"
                }),
                "batch_size": ("INT", {
                    "default": 1, "min": 1, "max": 8
                }),
                "aspect_ratio": (["Auto", "1:1", "9:16", "16:9", "21:9", "2:3", "3:2", "3:4", "4:3", "4:5", "5:4"], {
                    "default": "Auto"
                }),
            },
            "optional": {
                "seed": ("INT", {
                    "default": -1,
                    "min": -1,
                    "max": 102400,
                    "control_after_generate": True
                }),
                "top_p": ("FLOAT", {
                    "default": 0.95, "min": 0.0, "max": 1.0, "step": 0.01
                }),
                "image_1": ("IMAGE",),
                "image_2": ("IMAGE",),
                "image_3": ("IMAGE",),
                "image_4": ("IMAGE",),
                "image_5": ("IMAGE",),
            }
        }
    
    def _extract_numpy_images(self, tensor: torch.Tensor) -> List[np.ndarray]:
        """å°† Comfy å›¾åƒå¼ é‡è½¬æ¢ä¸ºæŒ‰æ‰¹æ¬¡å±•å¼€çš„ numpy å›¾åƒåˆ—è¡¨"""
        images: List[np.ndarray] = []
        if tensor is None:
            return images
        try:
            np_data = tensor.detach().cpu().numpy()
        except Exception as exc:
            logger.error(f"è¾“å…¥å›¾åƒè½¬æ¢å¤±è´¥: {exc}")
            return images

        if np_data.ndim == 3:
            np_data = np_data[np.newaxis, ...]
        np_data = np.clip(np_data, 0.0, 1.0)

        for sample in np_data:
            if sample.ndim == 2:
                sample = np.expand_dims(sample, axis=-1)
            if sample.shape[-1] == 1:
                sample = np.repeat(sample, 3, axis=-1)
            images.append(np.ascontiguousarray(sample))
        return images

    def tensor_to_base64(self, tensor: Optional[torch.Tensor] = None,
                         np_image: Optional[np.ndarray] = None) -> str:
        """å°† tensor æˆ– numpy å›¾åƒè½¬æ¢ä¸º base64"""
        if np_image is None:
            if tensor is None:
                raise ValueError("å¿…é¡»æä¾› tensor æˆ– numpy å›¾åƒæ•°æ®ç”¨äºç¼–ç ")
            samples = self._extract_numpy_images(tensor)
            if not samples:
                raise ValueError("æ— æ³•ä» tensor ä¸­æå–æœ‰æ•ˆå›¾åƒæ•°æ®")
            np_image = samples[0]

        img_array = np.clip(np_image, 0.0, 1.0)
        img_uint8 = (img_array * 255).astype(np.uint8)
        img = Image.fromarray(img_uint8)
        buffered = BytesIO()
        img.save(buffered, format="PNG")
        return base64.b64encode(buffered.getvalue()).decode()

    def prepare_input_images(self, tensors: List[torch.Tensor]) -> List[str]:
        """å°†è¾“å…¥tensoré¢„ç¼–ç ä¸ºBase64å¹¶å¤ç”¨ç¼“å­˜ï¼ˆæ”¯æŒæ‰¹é‡å›¾ç‰‡ï¼‰"""
        if not tensors:
            return []
        encoded_images: List[str] = []
        for tensor in tensors:
            if tensor is None:
                continue
            for sample in self._extract_numpy_images(tensor):
                cache_key = self._tensor_cache_key(np_data=sample)
                cached_value = self._get_cached_image_b64(cache_key)
                if cached_value is None:
                    base64_value = self.tensor_to_base64(np_image=sample)
                    self._set_cached_image_b64(cache_key, base64_value)
                else:
                    base64_value = cached_value
                encoded_images.append(base64_value)
        return encoded_images

    def base64_to_tensor_single(self, b64_str: str) -> np.ndarray:
        """å°†å•ä¸ªbase64è½¬æ¢ä¸ºnumpyæ•°ç»„"""
        try:
            img_data = base64.b64decode(b64_str)
            img = Image.open(BytesIO(img_data)).convert('RGB')
            img_array = np.array(img).astype(np.float32) / 255.0
            return img_array
        except Exception as e:
            logger.error(f"å›¾ç‰‡è§£ç å¤±è´¥: {str(e)}")
            # è¿”å›ä¸€ä¸ªå°çš„é”™è¯¯å ä½å›¾
            return np.zeros((64, 64, 3), dtype=np.float32)

    def base64_to_tensor_parallel(self, base64_strings: List[str],
                                  log_prefix: Optional[str] = None,
                                  max_workers: Optional[int] = None) -> torch.Tensor:
        """å¹¶å‘è§£ç å¤šå¼ å›¾ç‰‡,å¯é€‰è‡ªå®šä¹‰æ—¥å¿—å‰ç¼€"""
        # å®‰å…¨çš„åˆ—è¡¨ç©ºå€¼æ£€æŸ¥,é¿å…tensorå¸ƒå°”å€¼æ­§ä¹‰
        if not isinstance(base64_strings, list) or len(base64_strings) == 0:
            return torch.zeros((1, 64, 64, 3), dtype=torch.float32)
        
        decode_start = time.time()
        images = []
        worker_cap = max_workers if max_workers is not None else max(4, os.cpu_count() or 1)
        worker_cap = max(1, worker_cap)
        effective_workers = min(worker_cap, len(base64_strings))

        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘è§£ç 
        self._ensure_not_interrupted()
        executor = ThreadPoolExecutor(max_workers=effective_workers)
        try:
            future_to_index = {executor.submit(self.base64_to_tensor_single, b64): i 
                             for i, b64 in enumerate(base64_strings)}
            
            # æŒ‰é¡ºåºæ”¶é›†ç»“æœ
            results = [None] * len(base64_strings)
            try:
                for future in as_completed(future_to_index):
                    index = future_to_index[future]
                    try:
                        self._ensure_not_interrupted()
                        results[index] = future.result()
                    except comfy.model_management.InterruptProcessingException:
                        # æ£€æµ‹åˆ°ä¸­æ–­ï¼Œç«‹å³å–æ¶ˆæ‰€æœ‰æœªå®Œæˆçš„ä»»åŠ¡
                        for pending in future_to_index:
                            pending.cancel()
                        raise
                    except Exception as e:
                        logger.error(f"å›¾ç‰‡{index+1}è§£ç å¼‚å¸¸: {str(e)}")
                        results[index] = np.zeros((64, 64, 3), dtype=np.float32)

                images = [r for r in results if r is not None]
            except comfy.model_management.InterruptProcessingException:
                # ç¡®ä¿åœ¨ä¸­æ–­æ—¶å…³é—­çº¿ç¨‹æ± 
                executor.shutdown(wait=False, cancel_futures=True)
                raise
        finally:
            # ç¡®ä¿çº¿ç¨‹æ± è¢«å…³é—­
            if not executor._shutdown:
                executor.shutdown(wait=False, cancel_futures=True)

        decode_time = time.time() - decode_start
        logger.success(f"å¹¶å‘è§£ç  {len(images)} å¼ å›¾ç‰‡å®Œæˆï¼Œè€—æ—¶: {decode_time:.2f}s")

        return torch.from_numpy(np.stack(images))

    def _build_preview_tuple(self, tensor: Optional[torch.Tensor], batch_index: int,
                              max_size: int = 512) -> Optional[Tuple[str, Image.Image, int]]:
        """å°†ç”Ÿæˆç»“æœè½¬æ¢ä¸º ComfyUI æ‰€éœ€çš„å®æ—¶é¢„è§ˆæ ¼å¼"""
        if tensor is None or tensor.shape[0] == 0:
            return None

        try:
            preview_tensor = tensor[0].detach().cpu()
            preview_tensor = torch.clamp(preview_tensor, 0.0, 1.0)
            preview_array = (preview_tensor.numpy() * 255).astype(np.uint8)

            # å…¼å®¹å•é€šé“/Alpha é€šé“è¾“å‡º
            if preview_array.ndim == 3 and preview_array.shape[2] == 1:
                preview_array = np.repeat(preview_array, 3, axis=2)
            elif preview_array.ndim == 2:
                preview_array = np.stack([preview_array] * 3, axis=2)

            preview_image = Image.fromarray(preview_array)
            return ("PNG", preview_image, max_size)
        except Exception as e:
            logger.error(f"å®æ—¶é¢„è§ˆç”Ÿæˆå¤±è´¥: æ‰¹æ¬¡ {batch_index + 1}: {str(e)[:80]}")
            return None

    @staticmethod
    def _ensure_not_interrupted():
        """ç»Ÿä¸€çš„ä¸­æ–­æ£€æŸ¥ï¼Œå¤ç”¨ ComfyUI åŸç”Ÿå–æ¶ˆæœºåˆ¶"""
        comfy.model_management.throw_exception_if_processing_interrupted()

    def build_error_image_tensor(self, title: str, lines: List[str], size: Tuple[int, int] = (640, 640)) -> torch.Tensor:
        lines = [line.strip() for line in lines if line and line.strip()]
        if not lines:
            lines = ["å‘ç”ŸæœªçŸ¥é”™è¯¯"]

        width, height = size
        background = (248, 248, 248)
        accent = (255, 235, 235)
        title_color = (180, 30, 30)
        text_color = (45, 45, 45)

        img = Image.new("RGB", (width, height), background)
        draw = ImageDraw.Draw(img)
        font_title = self._load_error_font(26)
        font_body = self._load_error_font(18)

        margin = 32
        y = margin
        max_text_width = max(10, width - 2 * margin)
        max_y = height - margin

        def line_height(font: ImageFont.ImageFont) -> int:
            if hasattr(font, "getmetrics"):
                ascent, descent = font.getmetrics()
                return ascent + descent + 4
            if hasattr(font, "size"):
                return font.size + 4
            return 20

        title_text = title.strip() if title else "é”™è¯¯æç¤º"
        title_segments = self._wrap_text_segments(draw, title_text or "é”™è¯¯æç¤º", font_title, max_text_width) or ["é”™è¯¯æç¤º"]
        title_line_height = line_height(font_title)
        block_top = y - 6
        block_bottom = y + len(title_segments) * title_line_height + 6
        draw.rounded_rectangle([(margin - 10, block_top), (width - margin + 10, block_bottom)], radius=12, fill=accent)

        for segment in title_segments:
            draw.text((margin, y), segment, font=font_title, fill=title_color)
            y += title_line_height

        y += 6
        body_line_height = line_height(font_body)
        stop_render = False

        for line in lines:
            if stop_render:
                break
            segments = self._wrap_text_segments(draw, line, font_body, max_text_width) or [""]
            for segment in segments:
                if y > max_y:
                    stop_render = True
                    break
                draw.text((margin, y), segment, font=font_body, fill=text_color)
                y += body_line_height
            if stop_render:
                break
            y += 4

        arr = np.array(img).astype(np.float32) / 255.0
        return torch.from_numpy(arr).unsqueeze(0)

    def build_error_tensor_from_text(self, title: str, text: str) -> torch.Tensor:
        normalized = text.replace("\r\n", "\n").replace("\r", "\n")
        lines = [line.strip() for line in normalized.split("\n") if line.strip()]
        if not lines:
            lines = ["å‘ç”ŸæœªçŸ¥é”™è¯¯"]
        return self.build_error_image_tensor(title, lines)

    @classmethod
    def _get_error_font_paths(cls) -> List[str]:
        candidates = []
        windir = os.environ.get("WINDIR")
        if windir:
            for name in ("msyh.ttc", "msyh.ttf", "msjh.ttc", "simhei.ttf", "msmincho.ttc"):
                candidates.append(os.path.join(windir, "Fonts", name))
        candidates.append(os.path.join(os.path.dirname(__file__), "msyh.ttc"))
        return candidates

    @classmethod
    def _load_error_font(cls, size: int) -> ImageFont.ImageFont:
        cached = cls._ERROR_FONT_CACHE.get(size)
        if cached is not None:
            return cached
        for font_path in cls._get_error_font_paths():
            if font_path and os.path.exists(font_path):
                try:
                    font = ImageFont.truetype(font_path, size)
                    cls._ERROR_FONT_CACHE[size] = font
                    return font
                except Exception:
                    continue
        fallback = ImageFont.load_default()
        cls._ERROR_FONT_CACHE[size] = fallback
        return fallback

    def _wrap_text_segments(self, draw: ImageDraw.ImageDraw, text: str,
                            font: ImageFont.ImageFont, max_width: int) -> List[str]:
        if not text:
            return [""]
        segments: List[str] = []
        current = ""
        for ch in text:
            tentative = current + ch
            if draw.textlength(tentative, font=font) <= max_width or not current:
                current = tentative
            else:
                segments.append(current)
                current = ch
        if current:
            segments.append(current)
        return segments

    def create_request_data(self, prompt: str, seed: int, aspect_ratio: str,
                          top_p: float = 0.65, input_images_b64: Optional[List[str]] = None) -> Dict:
        """æ„å»ºè¯·æ±‚æ•°æ®"""
        if seed != -1:
            style_variations = [
                "detailed, high quality",
                "masterpiece, ultra detailed", 
                "photorealistic, stunning",
                "artistic, beautiful composition",
                "vibrant colors, sharp focus"
            ]
            style = style_variations[seed % len(style_variations)]
            final_prompt = f"{prompt}, {style}"
        else:
            final_prompt = prompt
            
        parts = [{"text": final_prompt}]
        
        if input_images_b64:
            for base64_image in input_images_b64:
                if base64_image:
                    parts.append({
                        "inlineData": {
                            "mimeType": "image/png",
                            "data": base64_image
                        }
                    })
        
        generation_config = {
            "responseModalities": ["IMAGE"],
            "temperature": 0.8,
            "topP": top_p,  # æ·»åŠ top_på‚æ•°
            "maxOutputTokens": 8192,
        }
        
        if aspect_ratio and aspect_ratio != "Auto":
            generation_config["imageConfig"] = {
                "aspectRatio": aspect_ratio
            }
        
        if seed != -1:
            generation_config["seed"] = seed
        
        return {
            "contents": [{
                "role": "user", 
                "parts": parts
            }],
            "generationConfig": generation_config
        }

    @retry_with_backoff(tries=2, delay=2, backoff=1, fast_fail_threshold=20.0)

    def send_request(self, api_key: str, request_data: Dict, model_type: str,
                    api_base_url: str, timeout = 180) -> Dict:
        """å‘é€APIè¯·æ±‚"""
        endpoint = "generateContent"

        if "generativelanguage.googleapis.com" in api_base_url:
            url = f"{api_base_url.rstrip('/')}/v1beta/models/{model_type}:{endpoint}?key={api_key}"
            headers = {'Content-Type': 'application/json'}
        else:
            url = f"{api_base_url.rstrip('/')}/v1beta/models/{model_type}:{endpoint}"
            headers = {
                'Content-Type': 'application/json',
                'Authorization': f'Bearer {api_key}',
            }

        headers['User-Agent'] = 'ComfyUI-Gemini-Node/2.1'

        request_start = time.time()
        # æ¯æ¬¡è¯·æ±‚ä½¿ç”¨ç‹¬ç«‹ Session,ä¸åˆå§‹ç‰ˆæœ¬è¡Œä¸ºä¿æŒä¸€è‡´
        session = requests.Session()
        session.headers.update(headers)
        try:
            response = session.post(url, json=request_data, timeout=timeout)
            request_time = time.time() - request_start
            try:
                if response.status_code != 200:
                    # è®°å½•é200å“åº”çš„è€—æ—¶ï¼Œå¸®åŠ©è¯Šæ–­
                    error_msg = f"APIè¿”å› {response.status_code}: {response.text[:200]}"
                    logger.warning(f"è¯·æ±‚è€—æ—¶ {request_time:.2f}s åæ”¶åˆ°é”™è¯¯: {error_msg}")
                    # è¿™é‡Œä»ç„¶æŠ›å‡ºé€šç”¨å¼‚å¸¸,ç”±é‡è¯•è£…é¥°å™¨æ ¹æ®é”™è¯¯ä¿¡æ¯å†³å®šæ˜¯å¦é‡è¯•
                    raise Exception(error_msg)
                logger.info(f"APIè¯·æ±‚æˆåŠŸï¼Œè€—æ—¶ {request_time:.2f}s")
                return response.json()
            finally:
                # ç¡®ä¿å“åº”å†…å®¹è¢«å®Œå…¨è¯»å–
                response.close()
        except requests.exceptions.Timeout as e:
            timeout_duration = time.time() - request_start
            # ä¿ç•™ Timeout å¼‚å¸¸ç±»å‹,è®©é‡è¯•è£…é¥°å™¨èƒ½å¤Ÿè¯†åˆ«ä¸ºå¯é‡è¯•é”™è¯¯
            msg = f"è¯·æ±‚è¶…æ—¶ï¼ˆè®¾ç½®{timeout}ç§’ï¼Œå®é™…ç­‰å¾…{timeout_duration:.1f}ç§’ï¼‰"
            logger.warning(msg)
            raise requests.exceptions.Timeout(msg) from e
        except requests.exceptions.RequestException as e:
            # å¯¹äºè¿æ¥ä¸­æ–­ã€å†™å…¥è¶…æ—¶ã€SSL EOF ç­‰ç½‘ç»œå¼‚å¸¸,
            # ä¿ç•™åŸå§‹ RequestException ç±»å‹,äº¤ç”±é‡è¯•è£…é¥°å™¨ç»Ÿä¸€å¤„ç†
            logger.warning(f"ç½‘ç»œé”™è¯¯: {str(e)}")
            raise
        finally:
            # ç‹¬ç«‹ Session ä½¿ç”¨å®Œåç«‹å³å…³é—­,é¿å…åœ¨ä»£ç†/ä¸ç¨³å®šç½‘ç»œä¸‹å¤ç”¨æ½œåœ¨åè¿æ¥
            session.close()

    def extract_content(self, response_data: Dict) -> Tuple[List[str], str]:
        """æå–å“åº”ä¸­çš„å›¾åƒå’Œæ–‡æœ¬"""
        base64_images = []
        text_content = ""
        
        candidates = response_data.get('candidates', [])
        if not candidates:
            raise ValueError("APIå“åº”ä¸­æ²¡æœ‰candidateså­—æ®µ")
        
        content = candidates[0].get('content', {})
        
        if content is None or content.get('parts') is None:
            return base64_images, text_content
        
        parts = content.get('parts', [])
        
        for part in parts:
            if 'text' in part:
                text_content += part['text']
            elif 'inlineData' in part and 'data' in part['inlineData']:
                base64_images.append(part['inlineData']['data'])
        
        if not base64_images and text_content:
            patterns = [
                r'data:image/[^;]+;base64,([A-Za-z0-9+/=]+)',
                r'!\[.*?\]\(data:image/[^;]+;base64,([A-Za-z0-9+/=]+)\)',
            ]
            for pattern in patterns:
                matches = re.findall(pattern, text_content)
                if matches:
                    base64_images.extend(matches)

        return base64_images, text_content.strip()

    def generate_single_image(self, args):
        """ç”Ÿæˆå•å¼ å›¾ç‰‡ï¼ˆç”¨äºå¹¶å‘ï¼‰"""
        (
            i,
            current_seed,
            api_key,
            prompt,
            model_type,
            aspect_ratio,
            top_p,
            input_images_b64,
            timeout,
            stagger_delay,
            decode_workers,
        ) = args

        self._ensure_not_interrupted()
        if stagger_delay > 0:
            delay = i * stagger_delay
            if delay > 0:
                time.sleep(delay)

        thread_id = threading.current_thread().name
        logger.info(f"æ‰¹æ¬¡ {i+1} å¼€å§‹è¯·æ±‚...")

        try:
            self._ensure_not_interrupted()
            request_data = self.create_request_data(prompt, current_seed, aspect_ratio, top_p, input_images_b64)
            self._ensure_not_interrupted()
            effective_base_url = type(self)._get_effective_api_base_url()
            response_data = self.send_request(api_key, request_data, model_type, effective_base_url, timeout)
            self._ensure_not_interrupted()
            base64_images, text_content = self.extract_content(response_data)
            decoded_tensor = None
            decoded_count = 0
            if base64_images:
                self._ensure_not_interrupted()
                decoded_tensor = self.base64_to_tensor_parallel(
                    base64_images,
                    log_prefix=f"[{thread_id}] æ‰¹æ¬¡ {i+1}",
                    max_workers=decode_workers
                )
                decoded_count = decoded_tensor.shape[0]

            # æ›´æ˜æ˜¾åœ°åŒºåˆ†â€œæœ‰å›¾è¿”å›â€å’Œâ€œæœªè¿”å›ä»»ä½•å›¾ç‰‡â€çš„æƒ…å†µ
            if decoded_count > 0:
                logger.success(f"æ‰¹æ¬¡ {i+1} å®Œæˆ - ç”Ÿæˆ {decoded_count} å¼ å›¾ç‰‡")
            else:
                # ç®€åŒ–æ—¥å¿—è¾“å‡º,å°½å¯èƒ½ç»™å‡ºç”¨æˆ·èƒ½ç†è§£çš„åŸå› è¯´æ˜
                reason = ""
                # 1. æ£€æŸ¥ finishReason ä¿¡æ¯
                try:
                    if isinstance(response_data, dict):
                        candidates = response_data.get("candidates") or []
                        if candidates and isinstance(candidates[0], dict):
                            finish_reason = candidates[0].get("finishReason") or ""
                            if finish_reason:
                                if finish_reason == "NO_IMAGE":
                                    reason = "æ¨¡å‹æœªç”Ÿæˆä»»ä½•å›¾ç‰‡ï¼ˆfinishReason=NO_IMAGEï¼Œä¸€èˆ¬è¡¨ç¤ºå½“å‰æç¤ºæˆ–å‚è€ƒå›¾ä¸è§¦å‘å›¾åƒè¾“å‡ºï¼Œå¯èƒ½æ˜¯å†…å®¹è¢«è¿‡æ»¤æˆ–æœªé€šè¿‡å®‰å…¨å®¡æŸ¥ï¼‰"
                                else:
                                    reason = f"æ¨¡å‹æœªç”Ÿæˆå›¾ç‰‡ï¼ˆfinishReason={finish_reason}ï¼‰"
                except Exception:
                    # å¦‚æœè§£æ finishReason å¤±è´¥,å¿½ç•¥å³å¯
                    pass

                # 2. å¦‚æœæœ‰æ–‡æœ¬å†…å®¹,è¡¥å……å±•ç¤ºä¸€å°æ®µ
                brief_text = (text_content or "").strip().replace("\n", " ")
                if brief_text:
                    if reason:
                        reason = f"{reason}ï¼›æ¨¡å‹è¿”å›æ–‡æœ¬: {brief_text[:100]}"
                    else:
                        reason = f"æ¨¡å‹ä»…è¿”å›æ–‡æœ¬: {brief_text[:100]}"

                # 3. éƒ½æ²¡æœ‰å°±ç»™ä¸€ä¸ªé€šç”¨è¯´æ˜
                if not reason:
                    reason = "æ¨¡å‹æœªç»™å‡ºå›¾ç‰‡æˆ–è¯´æ˜æ–‡æœ¬ï¼Œå¯èƒ½æ˜¯æœåŠ¡ç«¯ç­–ç•¥æˆ–å‚æ•°è®¾ç½®å¯¼è‡´æœ¬æ¬¡æœªäº§å‡ºå›¾ç‰‡"

                logger.warning(f"æ‰¹æ¬¡ {i+1} å®Œæˆï¼Œä½†æœªè¿”å›ä»»ä½•å›¾ç‰‡ã€‚{reason}")

            return {
                'index': i,
                'success': True,
                'images': base64_images,
                'tensor': decoded_tensor,
                'image_count': decoded_count,
                'text': text_content,
                'seed': current_seed
            }
        except comfy.model_management.InterruptProcessingException:
            logger.warning(f"æ‰¹æ¬¡ {i+1} å·²å–æ¶ˆ")
            raise
        except Exception as e:
            error_msg = str(e)[:200]
            logger.error(f"æ‰¹æ¬¡ {i+1} å¤±è´¥")
            logger.error(f"é”™è¯¯: {error_msg}")
            return {
                'index': i,
                'success': False,
                'error': error_msg,
                'seed': current_seed,
                'tensor': None,
                'image_count': 0
            }

    def generate_images(self, prompt, api_key="", model_type="gemini-2.5-flash-image",
                       batch_size=1, aspect_ratio="Auto", seed=-1, top_p=0.95, max_workers=None,
                       image_1=None, image_2=None, image_3=None,
                       image_4=None, image_5=None):

        # è§£æ API Keyï¼šä¼˜å…ˆä½¿ç”¨èŠ‚ç‚¹è¾“å…¥ï¼Œç•™ç©ºæ—¶å›é€€ config
        sanitized_input_key = self._sanitize_api_key(api_key)
        resolved_api_key = sanitized_input_key or self._sanitize_api_key(self.load_config())

        # éªŒè¯API key
        if not resolved_api_key:
            error_msg = "è¯·åœ¨ config.ini ä¸­é…ç½® API Key æˆ–åœ¨èŠ‚ç‚¹ä¸­å¡«å†™"
            logger.error(error_msg)
            error_tensor = self.build_error_tensor_from_text(
                "é…ç½®ç¼ºå¤±",
                f"{error_msg}\nè¯·åœ¨ config.ini æˆ–èŠ‚ç‚¹è¾“å…¥ä¸­å¡«å†™æœ‰æ•ˆ API Key"
            )
            return (error_tensor, error_msg)

        # ç»Ÿä¸€ä½¿ç”¨å†…éƒ¨éšè—çš„ Base URLï¼ˆä¸æ¥å—å‰ç«¯ä¼ å…¥ï¼‰
        effective_base_url = type(self)._get_effective_api_base_url()

        cost_factor = self.load_cost_factor_from_config()
        balance_summary = self.get_cached_balance_text(effective_base_url, resolved_api_key, cost_factor)

        start_time = time.time()
        raw_input_images = [image_1, image_2, image_3, image_4, image_5]
        input_tensors = [img for img in raw_input_images if img is not None]
        encoded_input_images = self.prepare_input_images(input_tensors)

        # å›ºå®šé…ç½®
        concurrent_mode = True   # æ€»æ˜¯å¼€å¯å¹¶å‘
        # ä¸ºç½‘ç»œè¯·æ±‚å¢åŠ è½»å¾®äº¤é”™å»¶è¿Ÿ,å‡å°‘ç¬æ—¶è¯·æ±‚å°–å³°
        stagger_delay = 0.2      # æ¯ä¸ªæ‰¹æ¬¡ç›¸å¯¹å‰ä¸€ä¸ªå»¶è¿Ÿ 0.2 ç§’
        # æ‹†åˆ†ç½‘ç»œè¶…æ—¶ï¼šè¿æ¥(20s) + è¯»å–(90s)
        # è¿æ¥è¶…æ—¶è®¾ç½®ä¸º20sï¼Œåœ¨ä»£ç†/ä¸ç¨³å®šç½‘ç»œä¸‹æ›´å®½å®¹
        # è¯»å–è¶…æ—¶ä¿æŒ90sï¼Œå› ä¸ºå›¾åƒç”Ÿæˆç¡®å®éœ€è¦æ—¶é—´
        connect_timeout = 20
        read_timeout = 90
        request_timeout = (connect_timeout, read_timeout)
        continue_on_error = True  # æ€»æ˜¯å®¹é”™
        configured_workers = self.load_max_workers_from_config()
        decode_workers = max(1, configured_workers)

        if seed == -1:
            base_seed = random.randint(0, 102400)
        else:
            base_seed = seed

        decoded_tensors: List[torch.Tensor] = []
        total_generated_images = 0
        all_texts: List[str] = []
        results: List[Dict[str, Any]] = []
        tasks: List[Tuple[Any, ...]] = []

        for i in range(batch_size):
            current_seed = base_seed + i if seed != -1 else -1
            tasks.append((i, current_seed, resolved_api_key, prompt, model_type, aspect_ratio,
                          top_p, encoded_input_images, request_timeout, stagger_delay,
                          decode_workers))

        # æ˜¾ç¤ºä»»åŠ¡å¼€å§‹ä¿¡æ¯
        logger.header("ğŸ¨ Gemini å›¾åƒç”Ÿæˆä»»åŠ¡")
        logger.info(f"æ‰¹æ¬¡æ•°é‡: {batch_size} å¼ ")
        logger.info(f"å›¾ç‰‡æ¯”ä¾‹: {aspect_ratio}")
        if seed != -1:
            logger.info(f"éšæœºç§å­: {seed}")
        if top_p != 0.95:
            logger.info(f"Top-P å‚æ•°: {top_p}")
        logger.separator()

        # åˆ›å»º ComfyUI è¿›åº¦æ¡ - ä¼šåŒæ—¶åœ¨ Web UI å’Œæ§åˆ¶å°æ˜¾ç¤º
        pbar = comfy.utils.ProgressBar(batch_size)
        self._ensure_not_interrupted()

        used_concurrency = concurrent_mode and batch_size > 1
        completed = 0

        if used_concurrency:
            # å¯¹ç½‘ç»œå¹¶å‘åšæ›´ä¿å®ˆé™æµï¼Œé™ä½è¿œç«¯æŠ–åŠ¨æ—¶çš„è¿é”é˜»å¡æ¦‚ç‡
            # network_workers_cap å¯é€šè¿‡ config.ini é…ç½®,é»˜è®¤ 4
            configured_network_cap = self.load_network_workers_cap_from_config()
            network_workers_cap = min(configured_workers, configured_network_cap)
            actual_workers = min(network_workers_cap, batch_size)
            # æ‰‹åŠ¨ç®¡ç†çº¿ç¨‹æ± ï¼Œé¿å…åœ¨è¶…æ—¶åœºæ™¯ä¸‹å›  wait=True é˜»å¡é€€å‡º
            executor = ThreadPoolExecutor(max_workers=actual_workers)
            try:
                future_to_index = {executor.submit(self.generate_single_image, task): task[0]
                                   for task in tasks}
                overall_timeout = connect_timeout + read_timeout + 20
                deadline = time.time() + overall_timeout
                pending_futures = set(future_to_index.keys())
                timed_out = False

                while pending_futures:
                    remaining = deadline - time.time()
                    if remaining <= 0:
                        timed_out = True
                        break

                    done, pending_futures = wait(
                        pending_futures,
                        timeout=max(0.1, remaining),
                        return_when=FIRST_COMPLETED
                    )

                    if not done:
                        continue

                    for future in done:
                        index = future_to_index.pop(future, -1)
                        try:
                            self._ensure_not_interrupted()
                            result = future.result()
                            results.append(result)
                            completed += 1

                            if result['success']:
                                logger.success(f"[{completed}/{batch_size}] æ‰¹æ¬¡ {result['index']+1} å®Œæˆ")
                            else:
                                logger.error(f"[{completed}/{batch_size}] æ‰¹æ¬¡ {result['index']+1} å¤±è´¥")

                            preview_tensor = result.get('tensor')
                            if result.get('success') and preview_tensor is not None:
                                preview_tuple = self._build_preview_tuple(preview_tensor, result['index'])
                                if preview_tuple is not None:
                                    pbar.update_absolute(completed, batch_size, preview_tuple)
                                else:
                                    pbar.update(1)
                            else:
                                pbar.update(1)
                        except comfy.model_management.InterruptProcessingException:
                            logger.warning("æ£€æµ‹åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨å–æ¶ˆå‰©ä½™ä»»åŠ¡...")
                            for pending in pending_futures:
                                pending.cancel()
                            for future_ref in future_to_index.keys():
                                future_ref.cancel()
                            raise
                        except Exception as e:
                            logger.error(f"æ‰¹æ¬¡ {index+1 if index>=0 else '?'} å¼‚å¸¸: {str(e)}")
                            results.append({
                                'index': index,
                                'success': False,
                                'error': str(e),
                                'tensor': None,
                                'image_count': 0
                            })

                if timed_out and pending_futures:
                    logger.warning(f"æ•´ä½“è¶…æ—¶ï¼å·²å®Œæˆ {completed}/{batch_size} ä¸ªä»»åŠ¡")
                    for future in pending_futures:
                        future.cancel()
            except Exception:
                raise
            finally:
                # å…³é”®ï¼šä¸ç­‰å¾…çº¿ç¨‹ç»“æŸä»¥å…å¡ä½ä¸»çº¿ç¨‹ï¼›è¿è¡Œä¸­çš„è¯·æ±‚ä¼šåœ¨åå°è‡ªè¡Œç»“æŸ
                executor.shutdown(wait=False, cancel_futures=True)
        else:
            for task in tasks:
                self._ensure_not_interrupted()
                result = self.generate_single_image(task)
                results.append(result)
                # æ˜¾ç¤ºæ‰¹æ¬¡å®Œæˆ
                if result['success']:
                    logger.success(f"[{task[0]+1}/{batch_size}] æ‰¹æ¬¡ {task[0]+1} å®Œæˆ")
                else:
                    logger.error(f"[{task[0]+1}/{batch_size}] æ‰¹æ¬¡ {task[0]+1} å¤±è´¥")

                # æ›´æ–° ComfyUI è¿›åº¦æ¡ï¼ˆå®æ—¶é¢„è§ˆï¼‰
                preview_tensor = result.get('tensor')
                if result.get('success') and preview_tensor is not None:
                    preview_tuple = self._build_preview_tuple(preview_tensor, task[0])
                    if preview_tuple is not None:
                        pbar.update_absolute(task[0]+1, batch_size, preview_tuple)
                    else:
                        pbar.update(1)
                else:
                    pbar.update(1)
                if not result['success'] and not continue_on_error:
                    logger.warning("é‡åˆ°é”™è¯¯ä¸”æœªå¼€å¯å®¹é”™ï¼Œåœæ­¢å¤„ç†")
                    break

        if not results:
            error_text = f"æœªç”Ÿæˆä»»ä½•å›¾åƒ\næ€»è€—æ—¶: {time.time() - start_time:.2f}s"
            if balance_summary:
                error_text = f"{balance_summary}\n\n{error_text}"
            logger.error(error_text)
            error_tensor = self.build_error_tensor_from_text("ç”Ÿæˆå¤±è´¥", error_text)
            return (error_tensor, error_text)

        results.sort(key=lambda x: x['index'])

        for result in results:
            if result.get('success'):
                tensor = result.get('tensor')
                if tensor is not None:
                    decoded_tensors.append(tensor)
                    total_generated_images += result.get('image_count', tensor.shape[0])
                if result.get('text'):
                    all_texts.append(f"[æ‰¹æ¬¡ {result['index']+1}] {result['text']}")
            else:
                error_msg = f"[æ‰¹æ¬¡ {result['index']+1}] âŒ {result.get('error', 'æœªçŸ¥é”™è¯¯')}"
                all_texts.append(error_msg)
                if not continue_on_error:
                    break

        total_time = time.time() - start_time

        if not decoded_tensors or total_generated_images == 0:
            error_text = f"æœªç”Ÿæˆä»»ä½•å›¾åƒ\næ€»è€—æ—¶: {total_time:.2f}s\n\n" + "\n".join(all_texts)
            if balance_summary:
                error_text = f"{balance_summary}\n\n{error_text}"
            logger.error(error_text)
            error_tensor = self.build_error_tensor_from_text("ç”Ÿæˆå¤±è´¥", error_text)
            return (error_tensor, error_text)

        if len(decoded_tensors) == 1:
            image_tensor = decoded_tensors[0]
        else:
            image_tensor = torch.cat(decoded_tensors, dim=0)

        actual_count = total_generated_images
        ratio_text = "è‡ªåŠ¨" if aspect_ratio == "Auto" else aspect_ratio
        success_info = f"âœ… æˆåŠŸç”Ÿæˆ {actual_count} å¼ å›¾åƒï¼ˆæ¯”ä¾‹: {ratio_text}ï¼‰"
        avg_time = total_time / actual_count if actual_count > 0 else 0
        time_info = f"æ€»è€—æ—¶: {total_time:.2f}sï¼Œå¹³å‡ {avg_time:.2f}s/å¼ "
        if actual_count != batch_size:
            time_info += f" âš ï¸ è¯·æ±‚{batch_size}å¼ ï¼Œå®é™…ç”Ÿæˆ{actual_count}å¼ "
            # è‹¥å®é™…ç”Ÿæˆæ•°é‡å°‘äºè¯·æ±‚æ•°é‡ï¼Œåœ¨æ—¥å¿—ä¸­é¢å¤–ç»™å‡ºæ˜æ˜¾æç¤º
            logger.warning(f"éƒ¨åˆ†æ‰¹æ¬¡æœªè¿”å›å›¾ç‰‡ï¼šè¯·æ±‚ {batch_size} å¼ ï¼Œå®é™…ä¸Šåªç”Ÿæˆ {actual_count} å¼ ï¼Œè¯·æŸ¥çœ‹ä¸Šæ–¹å„æ‰¹æ¬¡æ—¥å¿—ä¸­çš„â€œæœªè¿”å›ä»»ä½•å›¾ç‰‡â€æç¤º")

        combined_text = f"{success_info}\n{time_info}"
        if all_texts:
            combined_text += "\n\n" + "\n".join(all_texts)
        if balance_summary:
            combined_text = f"{balance_summary}\n\n{combined_text}"

        # æ˜¾ç¤ºå®Œæˆç»Ÿè®¡
        logger.summary("ä»»åŠ¡å®Œæˆ", {
            "æ€»æ‰¹æ¬¡": f"{batch_size} ä¸ª",
            "æˆåŠŸç”Ÿæˆ": f"{actual_count} å¼ ",
            "æ€»è€—æ—¶": f"{total_time:.2f}s",
            "å¹³å‡é€Ÿåº¦": f"{avg_time:.2f}s/å¼ "
        })

        return (image_tensor, combined_text)

# æ³¨å†ŒèŠ‚ç‚¹
NODE_CLASS_MAPPINGS = {"BananaImageNode": BananaImageNode}
NODE_DISPLAY_NAME_MAPPINGS = {"BananaImageNode": "å¿ƒå®â¤Banana"}

BananaImageNode.ensure_balance_route()


